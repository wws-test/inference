1. 修改网页上面 Launch Model 部分的download_hub，添加局域网模型下载选项

改造方案：
1) 前端改动：
   - 在download_hub下拉选项中添加"lan_repository"
   - 选择lan_repository时自动使用固定的下载服务器地址(192.2.29.9)

2) 后端改动：
   - 在worker.py的launch_builtin_model函数中添加"lan_repository"选项
   - 添加URL拼接逻辑：http://192.2.29.9/models/{model_name}
   - 使用现有的下载逻辑，只需修改下载URL

3) nginx配置：
   ```nginx
   server {
       listen 80;
       server_name 192.2.29.9;
       
       location /models/ {
           root /path/to/your/models;
           autoindex on;
       }
   }
   ```

4) 模型文件组织：
   - 在nginx服务器上创建/path/to/your/models目录
   - 按模型名称存放文件，例如：
     /path/to/your/models/
     ├── llama2-7b/
     ├── chatglm-6b/
     └── qwen-7b/


2. 手动部署方案 越简单越好  

3. 默认语言为汉语

4.
